{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d3bb94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full code for getting All_Articles, Top_Headlines and From that we will get (Keywords, Sentiment, Summary, \n",
    "#   Topic_Clasiification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589afdfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84d4bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from newsapi import NewsApiClient\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from newspaper import Article\n",
    "from keybert import KeyBERT\n",
    "from textblob import TextBlob\n",
    "import torch\n",
    "import json\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f98eba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sandeep\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0037a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('mrm8488/t5-base-finetuned-summarize-news')\n",
    "tokenizer = T5Tokenizer.from_pretrained('mrm8488/t5-base-finetuned-summarize-news',return_dict=True)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "543fb52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = tf.keras.models.load_model('text_classification_without_regions//')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e69b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {2:'Sports',3:'Politics',4:'Start-up',5:'Business',6:'Habitat',7:'Global Health',13:'Technology',14:'Travel',\n",
    "     15:'Gender Equality',16:'Art & Culture',19:'Social Movement',\n",
    "     20:'Local News',21:'Happy News',24:'Climate Crisis',25:'science',26:'Human Rights', \n",
    "     27:'Mental Health',28:'Biotech',29:'LGBT',\n",
    "     30:'France',31:'Education',32:'Cryptocurrency',33:'Human Stories'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76307ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6140141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkcalendar import Calendar\n",
    "from tkcalendar import DateEntry\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44dbe3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi = NewsApiClient(api_key='146cfc0db7b84967afa4fbb2d074ba21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "196f9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4090fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code for Top_Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b14a0bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "root.title('Results')\n",
    "root.geometry('1400x800')\n",
    "\n",
    "s = Label(root, text='Sources')\n",
    "s.pack()\n",
    "\n",
    "options = ['bbc-news','CNN','fox-news']\n",
    "\n",
    "clicked = StringVar()\n",
    "clicked.set(options[0])\n",
    "\n",
    "drop = OptionMenu(root, clicked, *options)\n",
    "drop.pack()\n",
    "\n",
    "def get():\n",
    "    top_headlines = newsapi.get_top_headlines(sources=clicked.get(),language='en')\n",
    "    top_hlines.config(state='normal')\n",
    "    top_hlines.delete('1.0', 'end')\n",
    "    top_hlines.insert('1.0', top_headlines['articles'])\n",
    "    top_hlines.config(state='disabled')\n",
    "\n",
    "button = Button( root , text = \"get\" , command = get ).pack()\n",
    "                    \n",
    "tlabel = Label(root, text='Top Headlines')\n",
    "tlabel.pack()\n",
    "top_hlines = Text(root, height=15, width=150)\n",
    "top_hlines.pack()\n",
    "\n",
    "\n",
    "ulabel = Label(root, text='Please give the desired url')\n",
    "ulabel.pack()\n",
    "\n",
    "utext = Text(root, height=2,width=150)\n",
    "utext.pack()\n",
    "\n",
    "def kss():\n",
    "    url = utext.get('1.0','end').strip()\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    article.nlp()\n",
    "    text = article.text\n",
    "    def clean_text(text):\n",
    "      text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "      text = text.lower()\n",
    "      text = text.split()\n",
    "      text = [word for word in text if not word in set(nltk.corpus.stopwords.words('english'))]\n",
    "      text = ' '.join(text)\n",
    "      return text\n",
    "    \n",
    "    kb = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "    keywords = kb.extract_keywords(text, stop_words='english')\n",
    "    \n",
    "    keys.config(state='normal')\n",
    "    keys.delete('1.0', 'end')\n",
    "    keys.insert('1.0', keywords)\n",
    "    keys.config(state='disabled')\n",
    "    \n",
    "    analysis = TextBlob(text)\n",
    "    a = analysis.polarity\n",
    "    def type():\n",
    "      if (a>0.2):\n",
    "        return(\"Positive\")\n",
    "      elif (a<0):\n",
    "        return(\"Negative\")\n",
    "      else:\n",
    "        return(\"Neutral\")\n",
    "    c = type()\n",
    "    \n",
    "    sent.config(state='normal')\n",
    "    sent.delete('1.0', 'end')\n",
    "    sent.insert('1.0', c)\n",
    "    sent.config(state='disabled')\n",
    "    \n",
    "    inputs = tokenizer.encode(\"summarize: \" + text,return_tensors='pt',max_length=512,truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=120, min_length=80, length_penalty=5., num_beams=2)\n",
    "    summary = tokenizer.decode(summary_ids[0])\n",
    "    \n",
    "    d = summary.split(\" \")\n",
    "    e = \" \".join(d[1:])\n",
    "    f = tokenize.sent_tokenize(e)\n",
    "    g = f[:3]\n",
    "    \n",
    "    summ.config(state='normal')\n",
    "    summ.delete('1.0', 'end')\n",
    "    summ.insert('1.0', g)\n",
    "    summ.config(state='disabled')\n",
    "    \n",
    "    k = [summary]\n",
    "    l = main.predict(k)\n",
    "    m = np.argsort(l)\n",
    "    n = m.tolist()\n",
    "    o = []\n",
    "    for i in range(len(n[0])):\n",
    "      last_item = n[0].pop()\n",
    "      o.insert(i, last_item)\n",
    "    p = o[:3]\n",
    "    def top():\n",
    "        for i in p:\n",
    "            return(d[i])\n",
    "    \n",
    "    topic.config(state='normal')\n",
    "    topic.delete('1.0', 'end')\n",
    "    topic.insert('1.0', top())\n",
    "    topic.config(state='disabled')\n",
    "    \n",
    "button = Button( root , text = \"get\" , command = kss ).pack()\n",
    "\n",
    "klabel = Label(root, text='Keywords')\n",
    "klabel.pack()\n",
    "\n",
    "keys = Text(root, height=1, width=150)\n",
    "keys.config(state='disabled', bg='#dddddd')\n",
    "keys.pack()\n",
    "\n",
    "xlabel = Label(root, text='Sentiment')\n",
    "xlabel.pack()\n",
    "\n",
    "sent = Text(root, height=1, width=150)\n",
    "sent.config(state='disabled', bg='#dddddd')\n",
    "sent.pack()\n",
    "\n",
    "ylabel = Label(root, text='Summary')\n",
    "ylabel.pack()\n",
    "\n",
    "summ = Text(root, height=6, width=150)\n",
    "summ.config(state='disabled', bg='#dddddd')\n",
    "summ.pack()\n",
    "\n",
    "zlabel = Label(root, text='Topic Classification')\n",
    "zlabel.pack()\n",
    "\n",
    "topic = Text(root, height=3, width=150)\n",
    "topic.config(state='disabled', bg='#dddddd')\n",
    "topic.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "269218d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below code for All_Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2b856ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "root.title('Results')\n",
    "root.geometry('1400x800')\n",
    "\n",
    "#plabel for domains\n",
    "p = Label(root, text='Domains')\n",
    "p.pack()\n",
    "\n",
    "opt = ['bbc.com','cnn.com','foxnews.com']\n",
    "\n",
    "click = StringVar()\n",
    "click.set(opt[0])\n",
    "\n",
    "drop = OptionMenu(root, click, *opt)\n",
    "drop.pack()\n",
    "\n",
    "#calendar for selecting from date\n",
    "cal_frame = Frame(root)\n",
    "cal_frame.pack()\n",
    "\n",
    "cal1=DateEntry(cal_frame, locale='en_US', date_pattern='mm/dd/y')\n",
    "cal1.grid(row=1,column=0,padx=15)\n",
    "st1 = datetime.strptime(str(cal1.get_date()), \"%Y-%m-%d\").strftime('%Y-%m-%d')\n",
    "\n",
    "# calendar for selecting to date\n",
    "cal2 = DateEntry(cal_frame, locale='en_US', date_pattern='mm/dd/y')\n",
    "cal2.grid(row=1,column=1,padx=15)\n",
    "st2 = datetime.strptime(str(cal2.get_date()), \"%Y-%m-%d\").strftime('%Y-%m-%d')\n",
    "\n",
    "def art():\n",
    "    all_articles = newsapi.get_everything(domains=click.get(),from_param=cal1.get_date(),to=cal2.get_date(),language='en',sort_by='relevancy',page=1)\n",
    "    articles.config(state='normal')\n",
    "    articles.delete('1.0', 'end')\n",
    "    articles.insert('1.0', all_articles['articles'])\n",
    "    articles.config(state='disabled')\n",
    "\n",
    "button = Button( root , text = \"get\" , command = art).pack()\n",
    "\n",
    "alabel = Label(root, text='All Articles')\n",
    "alabel.pack()\n",
    "articles = Text(root, height=10, width=150)\n",
    "articles.pack()\n",
    "\n",
    "ulabel = Label(root, text='Please give the desired url')\n",
    "ulabel.pack()\n",
    "utext = Text(root, height=2,width=150)\n",
    "utext.pack()\n",
    "\n",
    "def kss():\n",
    "    url = utext.get('1.0','end').strip()\n",
    "    article = Article(url)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    article.nlp()\n",
    "    text = article.text\n",
    "    def clean_text(text):\n",
    "      text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "      text = text.lower()\n",
    "      text = text.split()\n",
    "      text = [word for word in text if not word in set(nltk.corpus.stopwords.words('english'))]\n",
    "      text = ' '.join(text)\n",
    "      return text\n",
    "    \n",
    "    kb = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "    keywords = kb.extract_keywords(text, stop_words='english')\n",
    "    \n",
    "    keys.config(state='normal')\n",
    "    keys.delete('1.0', 'end')\n",
    "    keys.insert('1.0', keywords)\n",
    "    keys.config(state='disabled')\n",
    "    \n",
    "    analysis = TextBlob(text)\n",
    "    a = analysis.polarity\n",
    "    def type():\n",
    "      if (a>0.2):\n",
    "        return(\"Positive\")\n",
    "      elif (a<0):\n",
    "        return(\"Negative\")\n",
    "      else:\n",
    "        return(\"Neutral\")\n",
    "    c = type()\n",
    "    \n",
    "    sent.config(state='normal')\n",
    "    sent.delete('1.0', 'end')\n",
    "    sent.insert('1.0', c)\n",
    "    sent.config(state='disabled')\n",
    "    \n",
    "    inputs = tokenizer.encode(\"summarize: \" + text,return_tensors='pt',max_length=512,truncation=True)\n",
    "    summary_ids = model.generate(inputs, max_length=120, min_length=80, length_penalty=5., num_beams=2)\n",
    "    summary = tokenizer.decode(summary_ids[0])\n",
    "    \n",
    "    d = summary.split(\" \")\n",
    "    e = \" \".join(d[1:])\n",
    "    f = tokenize.sent_tokenize(e)\n",
    "    g = f[:3]\n",
    "    \n",
    "    summ.config(state='normal')\n",
    "    summ.delete('1.0', 'end')\n",
    "    summ.insert('1.0', g)\n",
    "    summ.config(state='disabled')\n",
    "\n",
    "    l = main.predict(g)\n",
    "    m = np.argsort(l)\n",
    "    n = m.tolist()\n",
    "    o = []\n",
    "    for i in range(len(n[0])):\n",
    "      last_item = n[0].pop()\n",
    "      o.insert(i, last_item)\n",
    "    p = o[:3]\n",
    "    def top():\n",
    "        for i in p:\n",
    "            return(d[i])\n",
    "    \n",
    "    topic.config(state='normal')\n",
    "    topic.delete('1.0', 'end')\n",
    "    topic.insert('1.0', top())\n",
    "    topic.config(state='disabled')\n",
    "    \n",
    "button = Button( root , text = \"get\" , command = kss ).pack()\n",
    "\n",
    "klabel = Label(root, text='Keywords')\n",
    "klabel.pack()\n",
    "\n",
    "keys = Text(root, height=2, width=150)\n",
    "keys.config(state='disabled', bg='#dddddd')\n",
    "keys.pack()\n",
    "\n",
    "xlabel = Label(root, text='Sentiment')\n",
    "xlabel.pack()\n",
    "\n",
    "sent = Text(root, height=1, width=150)\n",
    "sent.config(state='disabled', bg='#dddddd')\n",
    "sent.pack()\n",
    "\n",
    "ylabel = Label(root, text='Summary')\n",
    "ylabel.pack()\n",
    "\n",
    "summ = Text(root, height=6, width=150)\n",
    "summ.config(state='disabled', bg='#dddddd')\n",
    "summ.pack()\n",
    "\n",
    "zlabel = Label(root, text='Topic Classification')\n",
    "zlabel.pack()\n",
    "\n",
    "topic = Text(root, height=2, width=150)\n",
    "topic.config(state='disabled', bg='#dddddd')\n",
    "topic.pack()\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27dba28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
